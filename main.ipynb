{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 2\n",
    "\n",
    "- Deliverable 2 will be a NER (Named entity recognition system).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the data\n",
    "\n",
    "url = https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "\n",
    "\n",
    "Essential info about entities:\n",
    "\n",
    "```\n",
    "geo = Geographical Entity\n",
    "org = Organization\n",
    "per = Person\n",
    "gpe = Geopolitical Entity\n",
    "tim = Time indicator\n",
    "art = Artifact\n",
    "eve = Event\n",
    "nat = Natural Phenomenon\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:11.016579Z",
     "start_time": "2020-05-05T15:43:11.012243Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is located in the 'data' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:22.865464Z",
     "start_time": "2020-05-05T15:43:22.482990Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:50.431431Z",
     "start_time": "2020-05-05T15:43:50.418337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Park</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NaN</td>\n",
       "      <td>put</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1           NaN             of   IN      O\n",
       "2           NaN  demonstrators  NNS      O\n",
       "3           NaN           have  VBP      O\n",
       "4           NaN        marched  VBN      O\n",
       "..          ...            ...  ...    ...\n",
       "65          NaN           Hyde  NNP  B-geo\n",
       "66          NaN           Park  NNP  I-geo\n",
       "67          NaN              .    .      O\n",
       "68  Sentence: 4         Police  NNS      O\n",
       "69          NaN            put  VBD      O\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fill with \"Sentence: k\" for each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:24.000309Z",
     "start_time": "2020-05-05T14:07:23.916878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(set(data[\"Sentence #\"]))\n",
    "sentences[0] = \"nan\"\n",
    "sentences.sort()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:24.866376Z",
     "start_time": "2020-05-05T14:07:24.861661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentence: 1', 'Sentence: 10', 'Sentence: 100']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:25.213336Z",
     "start_time": "2020-05-05T14:07:25.153708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data[\"Tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:26.407180Z",
     "start_time": "2020-05-05T14:07:25.694653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAG: I-gpe\n",
      "1225    States\n",
      "1264     Korea\n",
      "2713      Binh\n",
      "2932     Ababa\n",
      "3466      City\n",
      "5241     Lanka\n",
      "5313     Korea\n",
      "5361     Korea\n",
      "5370     Korea\n",
      "5390     Korea\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-org\n",
      "97             Labor\n",
      "154    International\n",
      "215             IAEA\n",
      "234         European\n",
      "248             U.N.\n",
      "328        Bilfinger\n",
      "359      Royal-Dutch\n",
      "370            Shell\n",
      "543               al\n",
      "597               al\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-per\n",
      "271         Mahmoud\n",
      "272     Ahmadinejad\n",
      "332         Horbach\n",
      "444       Abdullahi\n",
      "445           Yusuf\n",
      "446           Ahmad\n",
      "966        Muhammad\n",
      "974          Khayam\n",
      "1106     Faridullah\n",
      "1107           Khan\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-nat\n",
      "2723       H5N1\n",
      "4554       H5N1\n",
      "5044       Jing\n",
      "5073       Jing\n",
      "5606       H5N1\n",
      "12506      SARS\n",
      "12508    Severe\n",
      "13162       HIV\n",
      "13164      AIDS\n",
      "22260      AIDS\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-gpe\n",
      "18     British\n",
      "102    English\n",
      "113    Britain\n",
      "126    British\n",
      "173       Iran\n",
      "181       Iran\n",
      "196    Iranian\n",
      "238       U.S.\n",
      "245       Iran\n",
      "259     Tehran\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-geo\n",
      "6        London\n",
      "12         Iraq\n",
      "65         Hyde\n",
      "94      Britain\n",
      "106    Brighton\n",
      "118        Iraq\n",
      "133      London\n",
      "146        Rome\n",
      "148       Paris\n",
      "151      Madrid\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-art\n",
      "263       Nuclear\n",
      "3769     Saltillo\n",
      "3810    Pentastar\n",
      "3814     Chrysler\n",
      "3816        Dodge\n",
      "3818         Jeep\n",
      "3820          Ram\n",
      "3863        Vioxx\n",
      "3951        Vioxx\n",
      "3962        Vioxx\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-eve\n",
      "4854      Summer\n",
      "4855    Olympics\n",
      "5036     Olympic\n",
      "5171      Medusa\n",
      "5764         War\n",
      "6730        Open\n",
      "6756     Classic\n",
      "6834        Open\n",
      "9990         War\n",
      "9991          II\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-nat\n",
      "5045            Jing\n",
      "5074            Jing\n",
      "12509          Acute\n",
      "12510    Respiratory\n",
      "12511       Syndrome\n",
      "22948        Katrina\n",
      "23055        Katrina\n",
      "29719        Katrina\n",
      "34813        Katrina\n",
      "68389        Katrina\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-org\n",
      "98        Party\n",
      "155      Atomic\n",
      "156      Energy\n",
      "157      Agency\n",
      "235       Union\n",
      "249    Security\n",
      "250     Council\n",
      "329      Berger\n",
      "360       Shell\n",
      "544       Qaida\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-tim\n",
      "1479       8\n",
      "1993       1\n",
      "4137       2\n",
      "4148       3\n",
      "4979      of\n",
      "4980    2005\n",
      "7896      25\n",
      "7897       ,\n",
      "7898    1995\n",
      "8254       7\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-eve\n",
      "4853          2012\n",
      "4887         Games\n",
      "5001         Games\n",
      "5035          2008\n",
      "5170     Operation\n",
      "5763          Gulf\n",
      "6729    Australian\n",
      "6755       Kooyong\n",
      "6833    Australian\n",
      "9989         World\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: O\n",
      "0         Thousands\n",
      "1                of\n",
      "2     demonstrators\n",
      "3              have\n",
      "4           marched\n",
      "5           through\n",
      "7                to\n",
      "8           protest\n",
      "9               the\n",
      "10              war\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-per\n",
      "42           Bush\n",
      "270     President\n",
      "331        Thomas\n",
      "443     President\n",
      "965       Prophet\n",
      "973          Omar\n",
      "997        Khayam\n",
      "1055       Khayam\n",
      "1105        Malik\n",
      "1240        Abdul\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-geo\n",
      "66            Park\n",
      "347          State\n",
      "350          State\n",
      "381          Delta\n",
      "561           Arab\n",
      "796           West\n",
      "797       Frontier\n",
      "798       Province\n",
      "1112    Waziristan\n",
      "1122           Wam\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-tim\n",
      "167    Wednesday\n",
      "211    Wednesday\n",
      "274      Tuesday\n",
      "341    Wednesday\n",
      "493    Wednesday\n",
      "654       Sunday\n",
      "679     Saturday\n",
      "684       Friday\n",
      "740     Saturday\n",
      "848     Thursday\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-art\n",
      "264     Non-Proliferation\n",
      "3811                  V-6\n",
      "4016               Simple\n",
      "4017                 Life\n",
      "4142              Morning\n",
      "4143              America\n",
      "5248               Mirror\n",
      "5923                   De\n",
      "5924               Gaulle\n",
      "5935        International\n",
      "Name: Word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for tag in set(data[\"Tag\"]):\n",
    "    print(\"\\nTAG:\",tag)\n",
    "    print(data[data[\"Tag\"] == tag][\"Word\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sentences do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:27.815294Z",
     "start_time": "2020-05-05T14:07:27.808503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Sentence: 47959\" in sentences, \"Sentence: 47960\" in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:42.675734Z",
     "start_time": "2020-05-05T14:07:42.672591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_formatter = \"Sentence: {}\"\n",
    "sentence_formatter.format(0) in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:44.193383Z",
     "start_time": "2020-05-05T14:07:44.189951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_formatter = \"Sentence: {}\"\n",
    "sentence_formatter.format(1) in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:44.474063Z",
     "start_time": "2020-05-05T14:07:44.471021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sentence: 1', 'Sentence: 2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "sentence_id      = sentence_formatter.format(i)\n",
    "sentence_id_next = sentence_formatter.format(i+1)\n",
    "sentence_id, sentence_id_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:44.798669Z",
     "start_time": "2020-05-05T14:07:44.764080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0], dtype='int64')\n",
      "Int64Index([24], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(data.index[data[\"Sentence #\"] == sentence_id])\n",
    "print(data.index[data[\"Sentence #\"] == sentence_id_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:46.813348Z",
     "start_time": "2020-05-05T14:07:46.776735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "end   =  data.index[data[\"Sentence #\"] == sentence_id_next][0]\n",
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:47.090322Z",
     "start_time": "2020-05-05T14:07:47.069311Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Sentence #\"][start:end] = sentence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:47.432914Z",
     "start_time": "2020-05-05T14:07:47.429106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Sentence: 1\n",
       "1     Sentence: 1\n",
       "2     Sentence: 1\n",
       "3     Sentence: 1\n",
       "4     Sentence: 1\n",
       "5     Sentence: 1\n",
       "6     Sentence: 1\n",
       "7     Sentence: 1\n",
       "8     Sentence: 1\n",
       "9     Sentence: 1\n",
       "10    Sentence: 1\n",
       "11    Sentence: 1\n",
       "12    Sentence: 1\n",
       "13    Sentence: 1\n",
       "14    Sentence: 1\n",
       "15    Sentence: 1\n",
       "16    Sentence: 1\n",
       "17    Sentence: 1\n",
       "18    Sentence: 1\n",
       "19    Sentence: 1\n",
       "20    Sentence: 1\n",
       "21    Sentence: 1\n",
       "22    Sentence: 1\n",
       "23    Sentence: 1\n",
       "Name: Sentence #, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence #\"][start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a subset and writting an identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:54.788621Z",
     "start_time": "2020-05-05T14:07:54.427362Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")\n",
    "\n",
    "last_n = 2000\n",
    "end   = data.index[data[\"Sentence #\"] == sentence_formatter.format(last_n)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:55.351782Z",
     "start_time": "2020-05-05T14:07:55.348813Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[0:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:55.629433Z",
     "start_time": "2020-05-05T14:07:55.619897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "n_sentences = len(list(set(data[\"Sentence #\"])))\n",
    "first_n = 1\n",
    "last_n = last_n -1\n",
    "print(n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:07.569498Z",
     "start_time": "2020-05-05T14:07:59.107346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 105 ms, total: 12.1 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "for s_id in  range(first_n, last_n):\n",
    "    print(\"current {}/{}\".format(s_id,last_n), end=\"\\r\")\n",
    "    sentence_id = sentence_formatter.format(s_id)\n",
    "    sentence_id_next = sentence_formatter.format(s_id + 1)\n",
    "    start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "    end   = data.index[data[\"Sentence #\"] == sentence_id_next][0]\n",
    "    data[\"Sentence #\"][start:end] = sentence_id\n",
    "    \n",
    "sentence_id = sentence_formatter.format(last_n)\n",
    "start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "end   = data.shape[0]\n",
    "data[\"Sentence #\"][start:end] = sentence_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:07.574107Z",
     "start_time": "2020-05-05T14:08:07.570959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.562269Z",
     "start_time": "2020-05-05T14:08:07.575850Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "for i in range(1,n_sentences):\n",
    "    s = sentence_formatter.format(i)\n",
    "    X.append(list(data[data[\"Sentence #\"]==s][\"Word\"].values))\n",
    "    Y.append(list(data[data[\"Sentence #\"]==s][\"Tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.567398Z",
     "start_time": "2020-05-05T14:08:15.563916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "xy = [\"{}/{}\".format(x,y) for x,y in zip(X[i],Y[i])]\n",
    "\" \".join(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.573987Z",
     "start_time": "2020-05-05T14:08:15.569071Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_to_pos(X):\n",
    "\n",
    "    word_to_pos = {}\n",
    "    i = 0\n",
    "    for s in X:\n",
    "        for w in s:\n",
    "            if w not in word_to_pos:\n",
    "                word_to_pos[w] = i\n",
    "                i +=1\n",
    "                \n",
    "    pos_to_word = {v: k for k, v in word_to_pos.items()}\n",
    "    return word_to_pos, pos_to_word\n",
    "            \n",
    "def build_tag_to_pos(Y):\n",
    "    tag_to_pos = {}\n",
    "    i = 0\n",
    "    for s in Y:\n",
    "        for t in s:\n",
    "            if t not in tag_to_pos:\n",
    "                tag_to_pos[t] = i\n",
    "                i +=1\n",
    "    pos_to_tag = {v: k for k, v in tag_to_pos.items()}\n",
    "\n",
    "    return tag_to_pos, pos_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.584465Z",
     "start_time": "2020-05-05T14:08:15.575588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7047, 17)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos, pos_to_word = build_word_to_pos(X)\n",
    "tag_to_pos, pos_to_tag  = build_tag_to_pos(Y)\n",
    "\n",
    "len(word_to_pos), len(tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.590178Z",
     "start_time": "2020-05-05T14:08:15.586718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-per': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-org': 5,\n",
       " 'I-org': 6,\n",
       " 'B-tim': 7,\n",
       " 'B-art': 8,\n",
       " 'I-art': 9,\n",
       " 'I-per': 10,\n",
       " 'I-gpe': 11,\n",
       " 'I-tim': 12,\n",
       " 'B-nat': 13,\n",
       " 'B-eve': 14,\n",
       " 'I-eve': 15,\n",
       " 'I-nat': 16}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.603562Z",
     "start_time": "2020-05-05T14:08:15.592209Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = [[word_to_pos[w] for w in s] for s in X]\n",
    "#Y = [[tag_to_pos[t] for t in s] for s in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[w for w in s] for s in X]\n",
    "Y = [[t for t in s] for s in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx, _, _ = train_test_split(np.arange(len(X)), np.arange(len(X)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [X[i] for i in train_idx]\n",
    "Y_train = [Y[i] for i in train_idx]\n",
    "X_val = [X[i] for i in val_idx]\n",
    "Y_val = [Y[i] for i in val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMM import HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(word_to_pos, tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:137: RuntimeWarning: divide by zero encountered in log\n",
      "  return {\"emission\":   np.log(probs[\"emission\"]),\n",
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:138: RuntimeWarning: divide by zero encountered in log\n",
      "  \"transition\": np.log(probs[\"transition\"]),\n",
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:139: RuntimeWarning: divide by zero encountered in log\n",
      "  \"final\":      np.log(probs[\"final\"]),\n",
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:140: RuntimeWarning: divide by zero encountered in log\n",
      "  \"initial\":    np.log(probs[\"initial\"])}\n"
     ]
    }
   ],
   "source": [
    "hmm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fe1db6083747d0b49c74eca570e2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:214: RuntimeWarning: invalid value encountered in subtract\n",
      "  state_posteriors[:, pos] = log_f_x[:, pos] + log_b_x[:, pos] - log_likelihood\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy posterior decode train data 0.9699934768427919\n"
     ]
    }
   ],
   "source": [
    "Y_hat = []\n",
    "for x in tqdm(X_train):\n",
    "    Y_hat.append(hmm.predict_labels(x))\n",
    "\n",
    "correct = 0\n",
    "total   = 0\n",
    "for y,y_hat in zip(Y_train,Y_hat):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct +=1\n",
    "\n",
    "print(\"Accuracy posterior decode train data\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1ebb3800944fdc8619b11e8b58840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy posterior decode validation data 0.8725318121983326\n"
     ]
    }
   ],
   "source": [
    "Y_hat = []\n",
    "for x in tqdm(X_val):\n",
    "    Y_hat.append(hmm.predict_labels(x))\n",
    "\n",
    "correct = 0\n",
    "total   = 0\n",
    "for y,y_hat in zip(Y_val,Y_hat):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct +=1\n",
    "\n",
    "print(\"Accuracy posterior decode validation data\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skseq\n",
    "from skseq.sequences import sequence\n",
    "from skseq.sequences.sequence import Sequence\n",
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence_list(X, y, word_to_pos, tag_to_pos):\n",
    "    # Generate x and y dicts\n",
    "    x_dict = LabelDictionary(word_to_pos.keys())\n",
    "    y_dict = LabelDictionary(tag_to_pos.keys())\n",
    "    # Generate SequenceList\n",
    "    seq_list = SequenceList(x_dict, y_dict)\n",
    "    # Add words/tags to sequencelist\n",
    "    for i in range(len(X)):\n",
    "        seq_list.add_sequence(X[i], y[i], x_dict, y_dict)\n",
    "    return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = generate_sequence_list(X_train, Y_train, word_to_pos, tag_to_pos)\n",
    "val_seq = generate_sequence_list(X_val, Y_val, word_to_pos, tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spc.StructuredPerceptron(word_to_pos, tag_to_pos, feature_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.781871\n",
      "Epoch: 1 Accuracy: 0.835900\n",
      "Epoch: 2 Accuracy: 0.867949\n",
      "Epoch: 3 Accuracy: 0.883973\n",
      "Epoch: 4 Accuracy: 0.909442\n",
      "Epoch: 5 Accuracy: 0.920786\n",
      "Epoch: 6 Accuracy: 0.920559\n",
      "Epoch: 7 Accuracy: 0.936782\n",
      "Epoch: 8 Accuracy: 0.942965\n",
      "Epoch: 9 Accuracy: 0.946624\n",
      "Epoch: 10 Accuracy: 0.947049\n",
      "Epoch: 11 Accuracy: 0.947730\n",
      "Epoch: 12 Accuracy: 0.951332\n",
      "Epoch: 13 Accuracy: 0.956068\n",
      "Epoch: 14 Accuracy: 0.957458\n",
      "CPU times: user 2min 53s, sys: 513 ms, total: 2min 53s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 15\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Egypt/0 had/0 been/0 asked/0 to/0 write/0 Asia/0 for/0 Angel/0 ./0 "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"Egypt had been asked to write Asia for Angel .\"\n",
    "new_seq = skseq.sequences.sequence.Sequence(x=p.split(), y=[int(0) for w in p.split()])\n",
    "new_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egypt/B-geo had/O been/O asked/O to/O write/O Asia/B-geo for/O Angel/O ./O '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.viterbi_decode(new_seq)[0].to_words(train_seq,\n",
    "                                       only_tag_translation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "pred_val = sp.viterbi_decode_corpus(val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_corpus(sequences, sequences_predictions):\n",
    "    \"\"\"Evaluate classification accuracy at corpus level, comparing with\n",
    "    gold standard.\"\"\"\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        pred = sequences_predictions[i]\n",
    "        for j, y_hat in enumerate(pred.y):\n",
    "            if sequence.y[j] == y_hat:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP -  Accuracy Train: 0.976 Validation: 0.943\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and print accuracies\n",
    "eval_train = evaluate_corpus(train_seq.seq_list, pred_train)\n",
    "eval_val = evaluate_corpus(val_seq.seq_list, pred_val)\n",
    "print(\"SP -  Accuracy Train: %.3f Validation: %.3f\"%(eval_train, eval_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_model(\"perceptron_15_iter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = spc.StructuredPerceptron(word_to_pos, tag_to_pos, feature_mapper)\n",
    "sp2.load_model(dir=\"perceptron_15_iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
