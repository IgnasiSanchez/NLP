{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 2\n",
    "\n",
    "- Deliverable 2 will be a NER (Named entity recognition system).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the data\n",
    "\n",
    "url = https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\n",
    "\n",
    "\n",
    "Essential info about entities:\n",
    "\n",
    "```\n",
    "geo = Geographical Entity\n",
    "org = Organization\n",
    "per = Person\n",
    "gpe = Geopolitical Entity\n",
    "tim = Time indicator\n",
    "art = Artifact\n",
    "eve = Event\n",
    "nat = Natural Phenomenon\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:11.016579Z",
     "start_time": "2020-05-05T15:43:11.012243Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from Spelling_Correction_c  import Spelling_Correction_c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is located in the 'data' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:22.865464Z",
     "start_time": "2020-05-05T15:43:22.482990Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:43:50.431431Z",
     "start_time": "2020-05-05T15:43:50.418337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hyde</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Park</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>Police</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NaN</td>\n",
       "      <td>put</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1           NaN             of   IN      O\n",
       "2           NaN  demonstrators  NNS      O\n",
       "3           NaN           have  VBP      O\n",
       "4           NaN        marched  VBN      O\n",
       "..          ...            ...  ...    ...\n",
       "65          NaN           Hyde  NNP  B-geo\n",
       "66          NaN           Park  NNP  I-geo\n",
       "67          NaN              .    .      O\n",
       "68  Sentence: 4         Police  NNS      O\n",
       "69          NaN            put  VBD      O\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fill with \"Sentence: k\" for each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:24.000309Z",
     "start_time": "2020-05-05T14:07:23.916878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47960"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(set(data[\"Sentence #\"]))\n",
    "sentences[0] = \"nan\"\n",
    "sentences.sort()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:24.866376Z",
     "start_time": "2020-05-05T14:07:24.861661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentence: 1', 'Sentence: 10', 'Sentence: 100']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:25.213336Z",
     "start_time": "2020-05-05T14:07:25.153708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-art',\n",
       " 'B-eve',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-nat',\n",
       " 'B-org',\n",
       " 'B-per',\n",
       " 'B-tim',\n",
       " 'I-art',\n",
       " 'I-eve',\n",
       " 'I-geo',\n",
       " 'I-gpe',\n",
       " 'I-nat',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'O'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data[\"Tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:26.407180Z",
     "start_time": "2020-05-05T14:07:25.694653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAG: O\n",
      "0         Thousands\n",
      "1                of\n",
      "2     demonstrators\n",
      "3              have\n",
      "4           marched\n",
      "5           through\n",
      "7                to\n",
      "8           protest\n",
      "9               the\n",
      "10              war\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-art\n",
      "264     Non-Proliferation\n",
      "3811                  V-6\n",
      "4016               Simple\n",
      "4017                 Life\n",
      "4142              Morning\n",
      "4143              America\n",
      "5248               Mirror\n",
      "5923                   De\n",
      "5924               Gaulle\n",
      "5935        International\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-eve\n",
      "4853          2012\n",
      "4887         Games\n",
      "5001         Games\n",
      "5035          2008\n",
      "5170     Operation\n",
      "5763          Gulf\n",
      "6729    Australian\n",
      "6755       Kooyong\n",
      "6833    Australian\n",
      "9989         World\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-geo\n",
      "66            Park\n",
      "347          State\n",
      "350          State\n",
      "381          Delta\n",
      "561           Arab\n",
      "796           West\n",
      "797       Frontier\n",
      "798       Province\n",
      "1112    Waziristan\n",
      "1122           Wam\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-org\n",
      "98        Party\n",
      "155      Atomic\n",
      "156      Energy\n",
      "157      Agency\n",
      "235       Union\n",
      "249    Security\n",
      "250     Council\n",
      "329      Berger\n",
      "360       Shell\n",
      "544       Qaida\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-tim\n",
      "167    Wednesday\n",
      "211    Wednesday\n",
      "274      Tuesday\n",
      "341    Wednesday\n",
      "493    Wednesday\n",
      "654       Sunday\n",
      "679     Saturday\n",
      "684       Friday\n",
      "740     Saturday\n",
      "848     Thursday\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-per\n",
      "42           Bush\n",
      "270     President\n",
      "331        Thomas\n",
      "443     President\n",
      "965       Prophet\n",
      "973          Omar\n",
      "997        Khayam\n",
      "1055       Khayam\n",
      "1105        Malik\n",
      "1240        Abdul\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-gpe\n",
      "18     British\n",
      "102    English\n",
      "113    Britain\n",
      "126    British\n",
      "173       Iran\n",
      "181       Iran\n",
      "196    Iranian\n",
      "238       U.S.\n",
      "245       Iran\n",
      "259     Tehran\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-nat\n",
      "5045            Jing\n",
      "5074            Jing\n",
      "12509          Acute\n",
      "12510    Respiratory\n",
      "12511       Syndrome\n",
      "22948        Katrina\n",
      "23055        Katrina\n",
      "29719        Katrina\n",
      "34813        Katrina\n",
      "68389        Katrina\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-geo\n",
      "6        London\n",
      "12         Iraq\n",
      "65         Hyde\n",
      "94      Britain\n",
      "106    Brighton\n",
      "118        Iraq\n",
      "133      London\n",
      "146        Rome\n",
      "148       Paris\n",
      "151      Madrid\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-per\n",
      "271         Mahmoud\n",
      "272     Ahmadinejad\n",
      "332         Horbach\n",
      "444       Abdullahi\n",
      "445           Yusuf\n",
      "446           Ahmad\n",
      "966        Muhammad\n",
      "974          Khayam\n",
      "1106     Faridullah\n",
      "1107           Khan\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-gpe\n",
      "1225    States\n",
      "1264     Korea\n",
      "2713      Binh\n",
      "2932     Ababa\n",
      "3466      City\n",
      "5241     Lanka\n",
      "5313     Korea\n",
      "5361     Korea\n",
      "5370     Korea\n",
      "5390     Korea\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-tim\n",
      "1479       8\n",
      "1993       1\n",
      "4137       2\n",
      "4148       3\n",
      "4979      of\n",
      "4980    2005\n",
      "7896      25\n",
      "7897       ,\n",
      "7898    1995\n",
      "8254       7\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-art\n",
      "263       Nuclear\n",
      "3769     Saltillo\n",
      "3810    Pentastar\n",
      "3814     Chrysler\n",
      "3816        Dodge\n",
      "3818         Jeep\n",
      "3820          Ram\n",
      "3863        Vioxx\n",
      "3951        Vioxx\n",
      "3962        Vioxx\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: I-eve\n",
      "4854      Summer\n",
      "4855    Olympics\n",
      "5036     Olympic\n",
      "5171      Medusa\n",
      "5764         War\n",
      "6730        Open\n",
      "6756     Classic\n",
      "6834        Open\n",
      "9990         War\n",
      "9991          II\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-nat\n",
      "2723       H5N1\n",
      "4554       H5N1\n",
      "5044       Jing\n",
      "5073       Jing\n",
      "5606       H5N1\n",
      "12506      SARS\n",
      "12508    Severe\n",
      "13162       HIV\n",
      "13164      AIDS\n",
      "22260      AIDS\n",
      "Name: Word, dtype: object\n",
      "\n",
      "TAG: B-org\n",
      "97             Labor\n",
      "154    International\n",
      "215             IAEA\n",
      "234         European\n",
      "248             U.N.\n",
      "328        Bilfinger\n",
      "359      Royal-Dutch\n",
      "370            Shell\n",
      "543               al\n",
      "597               al\n",
      "Name: Word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for tag in set(data[\"Tag\"]):\n",
    "    print(\"\\nTAG:\",tag)\n",
    "    print(data[data[\"Tag\"] == tag][\"Word\"][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sentences do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:27.815294Z",
     "start_time": "2020-05-05T14:07:27.808503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Sentence: 47959\" in sentences, \"Sentence: 47960\" in sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:42.675734Z",
     "start_time": "2020-05-05T14:07:42.672591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_formatter = \"Sentence: {}\"\n",
    "sentence_formatter.format(0) in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:44.193383Z",
     "start_time": "2020-05-05T14:07:44.189951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_formatter = \"Sentence: {}\"\n",
    "sentence_formatter.format(1) in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:44.474063Z",
     "start_time": "2020-05-05T14:07:44.471021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sentence: 1', 'Sentence: 2')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "sentence_id      = sentence_formatter.format(i)\n",
    "sentence_id_next = sentence_formatter.format(i+1)\n",
    "sentence_id, sentence_id_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:44.798669Z",
     "start_time": "2020-05-05T14:07:44.764080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0], dtype='int64')\n",
      "Int64Index([24], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(data.index[data[\"Sentence #\"] == sentence_id])\n",
    "print(data.index[data[\"Sentence #\"] == sentence_id_next])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:46.813348Z",
     "start_time": "2020-05-05T14:07:46.776735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "end   =  data.index[data[\"Sentence #\"] == sentence_id_next][0]\n",
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:47.090322Z",
     "start_time": "2020-05-05T14:07:47.069311Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Sentence #\"][start:end] = sentence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:47.432914Z",
     "start_time": "2020-05-05T14:07:47.429106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Sentence: 1\n",
       "1     Sentence: 1\n",
       "2     Sentence: 1\n",
       "3     Sentence: 1\n",
       "4     Sentence: 1\n",
       "5     Sentence: 1\n",
       "6     Sentence: 1\n",
       "7     Sentence: 1\n",
       "8     Sentence: 1\n",
       "9     Sentence: 1\n",
       "10    Sentence: 1\n",
       "11    Sentence: 1\n",
       "12    Sentence: 1\n",
       "13    Sentence: 1\n",
       "14    Sentence: 1\n",
       "15    Sentence: 1\n",
       "16    Sentence: 1\n",
       "17    Sentence: 1\n",
       "18    Sentence: 1\n",
       "19    Sentence: 1\n",
       "20    Sentence: 1\n",
       "21    Sentence: 1\n",
       "22    Sentence: 1\n",
       "23    Sentence: 1\n",
       "Name: Sentence #, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Sentence #\"][start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a subset and writting an identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:54.788621Z",
     "start_time": "2020-05-05T14:07:54.427362Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")\n",
    "\n",
    "last_n = 2000\n",
    "end   = data.index[data[\"Sentence #\"] == sentence_formatter.format(last_n)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:55.351782Z",
     "start_time": "2020-05-05T14:07:55.348813Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[0:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:07:55.629433Z",
     "start_time": "2020-05-05T14:07:55.619897Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "n_sentences = len(list(set(data[\"Sentence #\"])))\n",
    "first_n = 1\n",
    "last_n = last_n -1\n",
    "print(n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:07.569498Z",
     "start_time": "2020-05-05T14:07:59.107346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 133 ms, total: 16.1 s\n",
      "Wall time: 15.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "for s_id in  range(first_n, last_n):\n",
    "    print(\"current {}/{}\".format(s_id,last_n), end=\"\\r\")\n",
    "    sentence_id = sentence_formatter.format(s_id)\n",
    "    sentence_id_next = sentence_formatter.format(s_id + 1)\n",
    "    start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "    end   = data.index[data[\"Sentence #\"] == sentence_id_next][0]\n",
    "    data[\"Sentence #\"][start:end] = sentence_id\n",
    "    \n",
    "sentence_id = sentence_formatter.format(last_n)\n",
    "start = data.index[data[\"Sentence #\"] == sentence_id][0]\n",
    "end   = data.shape[0]\n",
    "data[\"Sentence #\"][start:end] = sentence_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:07.574107Z",
     "start_time": "2020-05-05T14:08:07.570959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.562269Z",
     "start_time": "2020-05-05T14:08:07.575850Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "sentence_formatter = \"Sentence: {}\"\n",
    "\n",
    "for i in range(1,n_sentences):\n",
    "    s = sentence_formatter.format(i)\n",
    "    X.append(list(data[data[\"Sentence #\"]==s][\"Word\"].values))\n",
    "    Y.append(list(data[data[\"Sentence #\"]==s][\"Tag\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.567398Z",
     "start_time": "2020-05-05T14:08:15.563916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "xy = [\"{}/{}\".format(x,y) for x,y in zip(X[i],Y[i])]\n",
    "\" \".join(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.573987Z",
     "start_time": "2020-05-05T14:08:15.569071Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_to_pos(X):\n",
    "\n",
    "    word_to_pos = {}\n",
    "    i = 0\n",
    "    for s in X:\n",
    "        for w in s:\n",
    "            if w not in word_to_pos:\n",
    "                word_to_pos[w] = i\n",
    "                i +=1\n",
    "                \n",
    "    pos_to_word = {v: k for k, v in word_to_pos.items()}\n",
    "    return word_to_pos, pos_to_word\n",
    "            \n",
    "def build_tag_to_pos(Y):\n",
    "    tag_to_pos = {}\n",
    "    i = 0\n",
    "    for s in Y:\n",
    "        for t in s:\n",
    "            if t not in tag_to_pos:\n",
    "                tag_to_pos[t] = i\n",
    "                i +=1\n",
    "    pos_to_tag = {v: k for k, v in tag_to_pos.items()}\n",
    "\n",
    "    return tag_to_pos, pos_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[w for w in s] for s in X]\n",
    "Y = [[t for t in s] for s in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_idx, val_idx, _, _ = train_test_split(np.arange(len(X)), np.arange(len(X)), test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = [X[i] for i in train_idx]\n",
    "Y_train = [Y[i] for i in train_idx]\n",
    "X_val = [X[i] for i in val_idx]\n",
    "Y_val = [Y[i] for i in val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.584465Z",
     "start_time": "2020-05-05T14:08:15.575588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6268, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos, pos_to_word = build_word_to_pos(X_train)\n",
    "tag_to_pos, pos_to_tag  = build_tag_to_pos(Y_train)\n",
    "\n",
    "len(word_to_pos), len(tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:08:15.590178Z",
     "start_time": "2020-05-05T14:08:15.586718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-gpe': 0,\n",
       " 'O': 1,\n",
       " 'B-tim': 2,\n",
       " 'B-geo': 3,\n",
       " 'B-per': 4,\n",
       " 'B-org': 5,\n",
       " 'I-per': 6,\n",
       " 'I-org': 7,\n",
       " 'B-art': 8,\n",
       " 'I-gpe': 9,\n",
       " 'I-geo': 10,\n",
       " 'I-tim': 11,\n",
       " 'B-nat': 12,\n",
       " 'I-nat': 13,\n",
       " 'I-art': 14,\n",
       " 'B-eve': 15,\n",
       " 'I-eve': 16}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in range(len(X_train)):\n",
    "    words = words + X_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/laia/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Load the words of our corpus\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "words2 = nltk.corpus.words.words()\n",
    "words2.extend(['online', 'Quora'])\n",
    "words.extend(words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the spelling correction object (it will create the BK tree)\n",
    "spelling_c = Spelling_Correction_c(words, tol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An', 'Algerian', 'man', 'made', 'I']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence =['An', 'Algerian', 'man', 'madee', 'I']\n",
    "sentence_cl = spelling_c.correct_text(sentence)\n",
    "\n",
    "sentence_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(len(X_val))\n",
    "X_val_cleaned = []\n",
    "for w in X_val:\n",
    "    print(i)\n",
    "    sentence = X_val[i]\n",
    "    sentence_cl = spelling_c.correct_text(sentence)\n",
    "    X_val_cleaned.append(sentence_cl)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMM import HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(word_to_pos, tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:137: RuntimeWarning: divide by zero encountered in log\n",
      "  return {\"emission\":   np.log(probs[\"emission\"]),\n",
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:138: RuntimeWarning: divide by zero encountered in log\n",
      "  \"transition\": np.log(probs[\"transition\"]),\n",
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:139: RuntimeWarning: divide by zero encountered in log\n",
      "  \"final\":      np.log(probs[\"final\"]),\n",
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:140: RuntimeWarning: divide by zero encountered in log\n",
      "  \"initial\":    np.log(probs[\"initial\"])}\n"
     ]
    }
   ],
   "source": [
    "hmm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee1ab6206b44f66aee080e0aa6d9ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laia/Escriptori/Master/NLP/Assignment2/NLP/HMM.py:214: RuntimeWarning: invalid value encountered in subtract\n",
      "  state_posteriors[:, pos] = log_f_x[:, pos] + log_b_x[:, pos] - log_likelihood\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy posterior decode train data 0.941660285317224\n"
     ]
    }
   ],
   "source": [
    "Y_hat = []\n",
    "for x in tqdm(X_train):\n",
    "    Y_hat.append(hmm.predict_labels(x))\n",
    "\n",
    "correct = 0\n",
    "total   = 0\n",
    "for y,y_hat in zip(Y_train,Y_hat):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct +=1\n",
    "\n",
    "print(\"Accuracy posterior decode train data\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3dc69b60744167be200e95ea7136bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  1\n",
      "Error:  2\n",
      "Error:  3\n",
      "Error:  4\n",
      "Error:  8\n",
      "Error:  9\n",
      "Error:  12\n",
      "Error:  13\n",
      "Error:  14\n",
      "Error:  15\n",
      "Error:  18\n",
      "Error:  19\n",
      "Error:  20\n",
      "Error:  21\n",
      "Error:  22\n",
      "Error:  23\n",
      "Error:  24\n",
      "Error:  25\n",
      "Error:  26\n",
      "Error:  28\n",
      "Error:  29\n",
      "Error:  30\n",
      "Error:  31\n",
      "Error:  32\n",
      "Error:  33\n",
      "Error:  34\n",
      "Error:  35\n",
      "Error:  37\n",
      "Error:  38\n",
      "Error:  39\n",
      "Error:  40\n",
      "Error:  41\n",
      "Error:  43\n",
      "Error:  44\n",
      "Error:  45\n",
      "Error:  46\n",
      "Error:  47\n",
      "Error:  48\n",
      "Error:  49\n",
      "Error:  53\n",
      "Error:  54\n",
      "Error:  55\n",
      "Error:  56\n",
      "Error:  57\n",
      "Error:  58\n",
      "Error:  59\n",
      "Error:  60\n",
      "Error:  61\n",
      "Error:  63\n",
      "Error:  64\n",
      "Error:  65\n",
      "Error:  66\n",
      "Error:  67\n",
      "Error:  69\n",
      "Error:  70\n",
      "Error:  71\n",
      "Error:  72\n",
      "Error:  73\n",
      "Error:  74\n",
      "Error:  75\n",
      "Error:  76\n",
      "Error:  77\n",
      "Error:  78\n",
      "Error:  79\n",
      "Error:  80\n",
      "Error:  81\n",
      "Error:  82\n",
      "Error:  83\n",
      "Error:  85\n",
      "Error:  86\n",
      "Error:  87\n",
      "Error:  90\n",
      "Error:  92\n",
      "Error:  94\n",
      "Error:  96\n",
      "Error:  97\n",
      "Error:  98\n",
      "Error:  100\n",
      "Error:  101\n",
      "Error:  103\n",
      "Error:  104\n",
      "Error:  105\n",
      "Error:  106\n",
      "Error:  107\n",
      "Error:  108\n",
      "Error:  109\n",
      "Error:  110\n",
      "Error:  111\n",
      "Error:  112\n",
      "Error:  113\n",
      "Error:  115\n",
      "Error:  116\n",
      "Error:  118\n",
      "Error:  119\n",
      "Error:  120\n",
      "Error:  121\n",
      "Error:  122\n",
      "Error:  123\n",
      "Error:  124\n",
      "Error:  125\n",
      "Error:  126\n",
      "Error:  127\n",
      "Error:  128\n",
      "Error:  130\n",
      "Error:  131\n",
      "Error:  132\n",
      "Error:  133\n",
      "Error:  134\n",
      "Error:  135\n",
      "Error:  139\n",
      "Error:  140\n",
      "Error:  141\n",
      "Error:  142\n",
      "Error:  143\n",
      "Error:  144\n",
      "Error:  145\n",
      "Error:  146\n",
      "Error:  147\n",
      "Error:  148\n",
      "Error:  149\n",
      "Error:  151\n",
      "Error:  152\n",
      "Error:  153\n",
      "Error:  154\n",
      "Error:  156\n",
      "Error:  157\n",
      "Error:  158\n",
      "Error:  164\n",
      "Error:  165\n",
      "Error:  166\n",
      "Error:  167\n",
      "Error:  169\n",
      "Error:  170\n",
      "Error:  172\n",
      "Error:  173\n",
      "Error:  175\n",
      "Error:  176\n",
      "Error:  177\n",
      "Error:  179\n",
      "Error:  180\n",
      "Error:  182\n",
      "Error:  183\n",
      "Error:  184\n",
      "Error:  186\n",
      "Error:  187\n",
      "Error:  188\n",
      "Error:  189\n",
      "Error:  190\n",
      "Error:  191\n",
      "Error:  192\n",
      "Error:  193\n",
      "Error:  194\n",
      "Error:  195\n",
      "Error:  196\n",
      "Error:  197\n",
      "Error:  198\n",
      "Error:  199\n",
      "Error:  200\n",
      "Error:  201\n",
      "Error:  202\n",
      "Error:  203\n",
      "Error:  204\n",
      "Error:  205\n",
      "Error:  206\n",
      "Error:  208\n",
      "Error:  209\n",
      "Error:  210\n",
      "Error:  211\n",
      "Error:  212\n",
      "Error:  213\n",
      "Error:  214\n",
      "Error:  215\n",
      "Error:  216\n",
      "Error:  218\n",
      "Error:  219\n",
      "Error:  221\n",
      "Error:  222\n",
      "Error:  227\n",
      "Error:  228\n",
      "Error:  229\n",
      "Error:  230\n",
      "Error:  231\n",
      "Error:  233\n",
      "Error:  234\n",
      "Error:  235\n",
      "Error:  236\n",
      "Error:  237\n",
      "Error:  238\n",
      "Error:  239\n",
      "Error:  243\n",
      "Error:  244\n",
      "Error:  245\n",
      "Error:  246\n",
      "Error:  247\n",
      "Error:  248\n",
      "Error:  249\n",
      "Error:  250\n",
      "Error:  251\n",
      "Error:  254\n",
      "Error:  255\n",
      "Error:  256\n",
      "Error:  257\n",
      "Error:  258\n",
      "Error:  260\n",
      "Error:  261\n",
      "Error:  262\n",
      "Error:  263\n",
      "Error:  264\n",
      "Error:  265\n",
      "Error:  267\n",
      "Error:  268\n",
      "Error:  269\n",
      "Error:  270\n",
      "Error:  271\n",
      "Error:  272\n",
      "Error:  273\n",
      "Error:  274\n",
      "Error:  275\n",
      "Error:  276\n",
      "Error:  277\n",
      "Error:  278\n",
      "Error:  279\n",
      "Error:  280\n",
      "Error:  281\n",
      "Error:  282\n",
      "Error:  283\n",
      "Error:  284\n",
      "Error:  285\n",
      "Error:  287\n",
      "Error:  289\n",
      "Error:  290\n",
      "Error:  292\n",
      "Error:  293\n",
      "Error:  294\n",
      "Error:  295\n",
      "Error:  296\n",
      "Error:  297\n",
      "Error:  298\n",
      "Error:  300\n",
      "Error:  301\n",
      "Error:  302\n",
      "Error:  305\n",
      "Error:  306\n",
      "Error:  307\n",
      "Error:  308\n",
      "Error:  309\n",
      "Error:  310\n",
      "Error:  311\n",
      "Error:  312\n",
      "Error:  313\n",
      "Error:  315\n",
      "Error:  316\n",
      "Error:  317\n",
      "Error:  319\n",
      "Error:  320\n",
      "Error:  321\n",
      "Error:  322\n",
      "Error:  323\n",
      "Error:  324\n",
      "Error:  325\n",
      "Error:  326\n",
      "Error:  327\n",
      "Error:  328\n",
      "Error:  330\n",
      "Error:  331\n",
      "Error:  332\n",
      "Error:  333\n",
      "Error:  334\n",
      "Error:  335\n",
      "Error:  336\n",
      "Error:  337\n",
      "Error:  338\n",
      "Error:  339\n",
      "Error:  341\n",
      "Error:  342\n",
      "Error:  343\n",
      "Error:  346\n",
      "Error:  347\n",
      "Error:  348\n",
      "Error:  349\n",
      "Error:  350\n",
      "Error:  352\n",
      "Error:  353\n",
      "Error:  355\n",
      "Error:  356\n",
      "Error:  357\n",
      "Error:  358\n",
      "Error:  359\n",
      "Error:  361\n",
      "Error:  362\n",
      "Error:  363\n",
      "Error:  365\n",
      "Error:  366\n",
      "Error:  367\n",
      "Error:  368\n",
      "Error:  369\n",
      "Error:  370\n",
      "Error:  371\n",
      "Error:  373\n",
      "Error:  374\n",
      "Error:  375\n",
      "Error:  376\n",
      "Error:  377\n",
      "Error:  378\n",
      "Error:  379\n",
      "Error:  380\n",
      "Error:  381\n",
      "Error:  382\n",
      "Error:  383\n",
      "Error:  384\n",
      "Error:  385\n",
      "Error:  387\n",
      "Error:  390\n",
      "Error:  392\n",
      "Error:  394\n",
      "Error:  395\n",
      "Error:  396\n",
      "Error:  397\n",
      "\n",
      "Accuracy posterior decode validation data 0.8814713896457765\n"
     ]
    }
   ],
   "source": [
    "Y_hat = []\n",
    "Y_val_new = []\n",
    "\n",
    "i=0\n",
    "for x in tqdm(X_val):\n",
    "    try:\n",
    "        Y_hat.append(hmm.predict_labels(x))\n",
    "        Y_val_new.append(Y_val[i])\n",
    "    except:\n",
    "        print(\"Error: \", i)\n",
    "    i+=1\n",
    "    \n",
    "correct = 0\n",
    "total   = 0\n",
    "for y,y_hat in zip(Y_val_new,Y_hat):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct +=1\n",
    "\n",
    "print(\"Accuracy posterior decode validation data\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f08181dba24cd6be9e7276a5743331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  1\n",
      "Error:  2\n",
      "Error:  3\n",
      "Error:  4\n",
      "Error:  8\n",
      "Error:  9\n",
      "Error:  12\n",
      "Error:  13\n",
      "Error:  14\n",
      "Error:  15\n",
      "Error:  18\n",
      "Error:  19\n",
      "Error:  20\n",
      "Error:  21\n",
      "Error:  22\n",
      "Error:  23\n",
      "Error:  24\n",
      "Error:  25\n",
      "Error:  26\n",
      "Error:  28\n",
      "Error:  29\n",
      "Error:  30\n",
      "Error:  31\n",
      "Error:  32\n",
      "Error:  33\n",
      "Error:  34\n",
      "Error:  35\n",
      "Error:  37\n",
      "Error:  38\n",
      "Error:  39\n",
      "Error:  40\n",
      "Error:  41\n",
      "Error:  43\n",
      "Error:  44\n",
      "Error:  45\n",
      "Error:  46\n",
      "Error:  47\n",
      "Error:  48\n",
      "Error:  49\n",
      "Error:  52\n",
      "Error:  53\n",
      "Error:  54\n",
      "Error:  55\n",
      "Error:  56\n",
      "Error:  57\n",
      "Error:  59\n",
      "Error:  60\n",
      "Error:  61\n",
      "Error:  63\n",
      "Error:  64\n",
      "Error:  65\n",
      "Error:  66\n",
      "Error:  67\n",
      "Error:  69\n",
      "Error:  70\n",
      "Error:  71\n",
      "Error:  72\n",
      "Error:  73\n",
      "Error:  74\n",
      "Error:  75\n",
      "Error:  76\n",
      "Error:  77\n",
      "Error:  78\n",
      "Error:  79\n",
      "Error:  80\n",
      "Error:  81\n",
      "Error:  82\n",
      "Error:  83\n",
      "Error:  85\n",
      "Error:  86\n",
      "Error:  87\n",
      "Error:  90\n",
      "Error:  92\n",
      "Error:  94\n",
      "Error:  96\n",
      "Error:  97\n",
      "Error:  98\n",
      "Error:  100\n",
      "Error:  101\n",
      "Error:  103\n",
      "Error:  104\n",
      "Error:  105\n",
      "Error:  106\n",
      "Error:  107\n",
      "Error:  108\n",
      "Error:  109\n",
      "Error:  110\n",
      "Error:  111\n",
      "Error:  112\n",
      "Error:  113\n",
      "Error:  115\n",
      "Error:  116\n",
      "Error:  118\n",
      "Error:  119\n",
      "Error:  120\n",
      "Error:  121\n",
      "Error:  122\n",
      "Error:  124\n",
      "Error:  125\n",
      "Error:  126\n",
      "Error:  127\n",
      "Error:  128\n",
      "Error:  130\n",
      "Error:  131\n",
      "Error:  132\n",
      "Error:  133\n",
      "Error:  134\n",
      "Error:  135\n",
      "Error:  139\n",
      "Error:  140\n",
      "Error:  141\n",
      "Error:  142\n",
      "Error:  143\n",
      "Error:  144\n",
      "Error:  145\n",
      "Error:  146\n",
      "Error:  147\n",
      "Error:  148\n",
      "Error:  149\n",
      "Error:  151\n",
      "Error:  152\n",
      "Error:  153\n",
      "Error:  154\n",
      "Error:  156\n",
      "Error:  157\n",
      "Error:  158\n",
      "Error:  160\n",
      "Error:  164\n",
      "Error:  165\n",
      "Error:  166\n",
      "Error:  167\n",
      "Error:  168\n",
      "Error:  169\n",
      "Error:  170\n",
      "Error:  172\n",
      "Error:  173\n",
      "Error:  175\n",
      "Error:  176\n",
      "Error:  177\n",
      "Error:  179\n",
      "Error:  180\n",
      "Error:  182\n",
      "Error:  183\n",
      "Error:  184\n",
      "Error:  186\n",
      "Error:  187\n",
      "Error:  188\n",
      "Error:  189\n",
      "Error:  190\n",
      "Error:  191\n",
      "Error:  192\n",
      "Error:  193\n",
      "Error:  194\n",
      "Error:  195\n",
      "Error:  196\n",
      "Error:  197\n",
      "Error:  198\n",
      "Error:  199\n",
      "Error:  200\n",
      "Error:  201\n",
      "Error:  202\n",
      "Error:  203\n",
      "Error:  204\n",
      "Error:  205\n",
      "Error:  208\n",
      "Error:  209\n",
      "Error:  210\n",
      "Error:  211\n",
      "Error:  212\n",
      "Error:  214\n",
      "Error:  215\n",
      "Error:  216\n",
      "Error:  218\n",
      "Error:  219\n",
      "Error:  221\n",
      "Error:  222\n",
      "Error:  225\n",
      "Error:  227\n",
      "Error:  228\n",
      "Error:  229\n",
      "Error:  230\n",
      "Error:  231\n",
      "Error:  233\n",
      "Error:  234\n",
      "Error:  235\n",
      "Error:  236\n",
      "Error:  237\n",
      "Error:  238\n",
      "Error:  239\n",
      "Error:  243\n",
      "Error:  244\n",
      "Error:  245\n",
      "Error:  246\n",
      "Error:  247\n",
      "Error:  248\n",
      "Error:  249\n",
      "Error:  250\n",
      "Error:  251\n",
      "Error:  254\n",
      "Error:  255\n",
      "Error:  256\n",
      "Error:  257\n",
      "Error:  258\n",
      "Error:  260\n",
      "Error:  261\n",
      "Error:  262\n",
      "Error:  263\n",
      "Error:  264\n",
      "Error:  265\n",
      "Error:  267\n",
      "Error:  268\n",
      "Error:  269\n",
      "Error:  270\n",
      "Error:  271\n",
      "Error:  272\n",
      "Error:  273\n",
      "Error:  274\n",
      "Error:  275\n",
      "Error:  276\n",
      "Error:  277\n",
      "Error:  278\n",
      "Error:  279\n",
      "Error:  280\n",
      "Error:  281\n",
      "Error:  282\n",
      "Error:  283\n",
      "Error:  284\n",
      "Error:  285\n",
      "Error:  287\n",
      "Error:  288\n",
      "Error:  289\n",
      "Error:  290\n",
      "Error:  292\n",
      "Error:  293\n",
      "Error:  294\n",
      "Error:  295\n",
      "Error:  296\n",
      "Error:  297\n",
      "Error:  298\n",
      "Error:  300\n",
      "Error:  301\n",
      "Error:  302\n",
      "Error:  304\n",
      "Error:  305\n",
      "Error:  306\n",
      "Error:  307\n",
      "Error:  308\n",
      "Error:  309\n",
      "Error:  310\n",
      "Error:  311\n",
      "Error:  312\n",
      "Error:  313\n",
      "Error:  315\n",
      "Error:  316\n",
      "Error:  317\n",
      "Error:  319\n",
      "Error:  320\n",
      "Error:  321\n",
      "Error:  322\n",
      "Error:  323\n",
      "Error:  324\n",
      "Error:  325\n",
      "Error:  326\n",
      "Error:  327\n",
      "Error:  328\n",
      "Error:  330\n",
      "Error:  331\n",
      "Error:  332\n",
      "Error:  333\n",
      "Error:  334\n",
      "Error:  335\n",
      "Error:  336\n",
      "Error:  337\n",
      "Error:  338\n",
      "Error:  341\n",
      "Error:  342\n",
      "Error:  343\n",
      "Error:  346\n",
      "Error:  347\n",
      "Error:  348\n",
      "Error:  349\n",
      "Error:  350\n",
      "Error:  352\n",
      "Error:  353\n",
      "Error:  355\n",
      "Error:  356\n",
      "Error:  357\n",
      "Error:  358\n",
      "Error:  359\n",
      "Error:  361\n",
      "Error:  362\n",
      "Error:  363\n",
      "Error:  365\n",
      "Error:  366\n",
      "Error:  367\n",
      "Error:  368\n",
      "Error:  369\n",
      "Error:  370\n",
      "Error:  371\n",
      "Error:  372\n",
      "Error:  373\n",
      "Error:  374\n",
      "Error:  375\n",
      "Error:  376\n",
      "Error:  377\n",
      "Error:  378\n",
      "Error:  379\n",
      "Error:  380\n",
      "Error:  381\n",
      "Error:  382\n",
      "Error:  383\n",
      "Error:  384\n",
      "Error:  385\n",
      "Error:  387\n",
      "Error:  388\n",
      "Error:  390\n",
      "Error:  392\n",
      "Error:  394\n",
      "Error:  395\n",
      "Error:  396\n",
      "Error:  397\n",
      "\n",
      "Accuracy posterior decode validation data (cleaned) 0.875629043853343\n"
     ]
    }
   ],
   "source": [
    "Y_hat_cleaned = []\n",
    "Y_val_cleaned = []\n",
    "i=0\n",
    "for x in tqdm(X_val_cleaned):\n",
    "    try:\n",
    "        Y_hat_cleaned.append(hmm.predict_labels(x))\n",
    "        Y_val_cleaned.append(Y_val[i])\n",
    "    except:\n",
    "        print(\"Error: \", i)\n",
    "    i+=1\n",
    "        \n",
    "correct = 0\n",
    "total   = 0\n",
    "for y,y_hat in zip(Y_val_cleaned,Y_hat_cleaned):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct +=1\n",
    "\n",
    "print(\"Accuracy posterior decode validation data (cleaned)\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skseq\n",
    "from skseq.sequences import sequence\n",
    "from skseq.sequences.sequence import Sequence\n",
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence_list(X, y, word_to_pos, tag_to_pos):\n",
    "    # Generate x and y dicts\n",
    "    x_dict = LabelDictionary(word_to_pos.keys())\n",
    "    y_dict = LabelDictionary(tag_to_pos.keys())\n",
    "    # Generate SequenceList\n",
    "    seq_list = SequenceList(x_dict, y_dict)\n",
    "    # Add words/tags to sequencelist\n",
    "    for i in range(len(X)):\n",
    "        seq_list.add_sequence(X[i], y[i], x_dict, y_dict)\n",
    "    return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = generate_sequence_list(X_train, Y_train, word_to_pos, tag_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spc.StructuredPerceptron(word_to_pos, tag_to_pos, feature_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.780283\n",
      "Epoch: 1 Accuracy: 0.838339\n",
      "Epoch: 2 Accuracy: 0.865907\n",
      "Epoch: 3 Accuracy: 0.889730\n",
      "Epoch: 4 Accuracy: 0.905471\n",
      "Epoch: 5 Accuracy: 0.914490\n",
      "Epoch: 6 Accuracy: 0.924076\n",
      "Epoch: 7 Accuracy: 0.935421\n",
      "Epoch: 8 Accuracy: 0.937463\n",
      "Epoch: 9 Accuracy: 0.945461\n",
      "Epoch: 10 Accuracy: 0.950651\n",
      "Epoch: 11 Accuracy: 0.955529\n",
      "Epoch: 12 Accuracy: 0.955359\n",
      "Epoch: 13 Accuracy: 0.954678\n",
      "Epoch: 14 Accuracy: 0.960237\n",
      "CPU times: user 4min 19s, sys: 455 ms, total: 4min 19s\n",
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 15\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Egypt/0 had/0 been/0 asked/0 to/0 write/0 Asia/0 for/0 Angel/0 hlashfo/0 ./0 "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"Egypt had been asked to write Asia for Angel hlashfo .\"\n",
    "new_seq = skseq.sequences.sequence.Sequence(x=p.split(), y=[int(0) for w in p.split()])\n",
    "new_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egypt/B-geo had/O been/O asked/O to/O write/O Asia/B-geo for/O Angel/O hlashfo/O ./O '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.viterbi_decode(new_seq)[0].to_words(train_seq,\n",
    "                                       only_tag_translation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_cleaned = []\n",
    "for i in range(len(X_val_cleaned)):\n",
    "    p = X_val_cleaned[i]\n",
    "    new_seq = skseq.sequences.sequence.Sequence(x=p, y=[int(0) for w in p])\n",
    "    res = sp.viterbi_decode(new_seq)[0]\n",
    "    pred_val_cleaned.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = []\n",
    "for i in range(len(X_val)):\n",
    "    p = X_val[i]\n",
    "    new_seq = skseq.sequences.sequence.Sequence(x=p, y=[int(0) for w in p])\n",
    "    res = sp.viterbi_decode(new_seq)[0]\n",
    "    pred_val.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = sp.viterbi_decode_corpus(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_corpus(sequences, sequences_predictions):\n",
    "    \"\"\"Evaluate classification accuracy at corpus level, comparing with\n",
    "    gold standard.\"\"\"\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        pred = sequences_predictions[i]\n",
    "        for j, y_hat in enumerate(pred.y):\n",
    "            if sequence.y[j] == y_hat:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_seq, sequences_predictions):\n",
    "    \"\"\"Evaluate classification accuracy at corpus level, comparing with\n",
    "    gold standard.\"\"\"\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    for i, ys in enumerate(y_seq):\n",
    "        pred = sequences_predictions[i]\n",
    "        for j, y_hat in enumerate(pred.y):\n",
    "            if tag_to_pos[ys[j]] == y_hat:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP -  Accuracy Train: 0.973 Validation: 0.939, Validation cleaned: 0.937\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and print accuracies\n",
    "eval_train = evaluate_corpus(train_seq.seq_list, pred_train)\n",
    "eval_val = evaluate_predictions(Y_val, pred_val)\n",
    "eval_val_cleaned = evaluate_predictions(Y_val, pred_val_cleaned)\n",
    "print(\"SP -  Accuracy Train: %.3f Validation: %.3f, Validation cleaned: %.3f\"%(eval_train, eval_val, eval_val_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_model(\"perceptron_15_iter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = spc.StructuredPerceptron(word_to_pos, tag_to_pos, feature_mapper)\n",
    "sp2.load_model(dir=\"perceptron_15_iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
